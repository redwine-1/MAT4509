\subsection{Part I: The Regression Equation for a Single Dependent Variable}

In simple linear regression, the model is defined by the following equation:

\begin{equation}
    \hat{y} = \beta_0 + \beta_1 x + \epsilon
\end{equation}

where:
\begin{itemize}
    \item \(\hat{y}\): The predicted or estimated value of the dependent variable, representing the outcome of interest.
    \item \(\beta_0\): The intercept term, which is the expected value of \(\hat{y}\) when \(x = 0\). This is a constant that shifts the regression line up or down.
    \item \(\beta_1\): The slope coefficient, representing the change in the predicted value \(\hat{y}\) for a one-unit increase in the independent variable \(x\). It quantifies the strength and direction of the relationship between \(x\) and \(\hat{y}\).
    \item \(x\): The independent variable (or predictor), which influences the dependent variable \(\hat{y}\). This variable is assumed to be measured without error.
    \item \(\epsilon\): The error term or residual, which accounts for the variation in \(\hat{y}\) that cannot be explained by the linear relationship with \(x\). It represents random deviations from the predicted values.
\end{itemize}
